{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DJNMJv9YzZEJ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib import style\n",
    "\n",
    "# sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# tensorflow and keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, GlobalAveragePooling2D\n",
    "from keras.models import model_from_yaml, Model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import plot_model\n",
    "from keras.models import save_model\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras.utils import  to_categorical\n",
    "from keras.preprocessing.image import img_to_array, array_to_img\n",
    "\n",
    "\n",
    "# transfer learning -- InceptionV3\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "\n",
    "# other\n",
    "from pprint import pprint\n",
    "from joblib import dump, load\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "mO0e2Gw-Ayhs",
    "outputId": "ba1adc66-7723-4529-f018-3ac51bf6fa67"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"fashion-mnist_train.csv\")\n",
    "test = pd.read_csv(\"fashion-mnist_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "id": "sWQZLxI08ABs",
    "outputId": "f9c0484d-b2ce-49ff-df7d-9d2870c0d603"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>203</td>\n",
       "      <td>214</td>\n",
       "      <td>166</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      2       0       0       0       0       0       0       0       0   \n",
       "1      9       0       0       0       0       0       0       0       0   \n",
       "2      6       0       0       0       0       0       0       0       5   \n",
       "3      0       0       0       0       1       2       0       0       0   \n",
       "4      3       0       0       0       0       0       0       0       0   \n",
       "5      4       0       0       0       5       4       5       5       3   \n",
       "6      4       0       0       0       0       0       0       0       0   \n",
       "7      5       0       0       0       0       0       0       0       0   \n",
       "8      4       0       0       0       0       0       0       3       2   \n",
       "9      8       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9    ...     pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0        30        43   \n",
       "3       0    ...            3         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "5       5    ...            7         8         7         4         3   \n",
       "6       0    ...           14         0         0         0         0   \n",
       "7       0    ...            0         0         0         0         0   \n",
       "8       0    ...            1         0         0         0         0   \n",
       "9       0    ...          203       214       166         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  pixel784  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         1         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "5         7         5         0         0         0  \n",
       "6         0         0         0         0         0  \n",
       "7         0         0         0         0         0  \n",
       "8         0         0         0         0         0  \n",
       "9         0         0         0         0         0  \n",
       "\n",
       "[10 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "4QaEu9Zq8CbW",
    "outputId": "08874814-d339-4333-91e4-3ff65dcb0570"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9    6000\n",
       "8    6000\n",
       "7    6000\n",
       "6    6000\n",
       "5    6000\n",
       "4    6000\n",
       "3    6000\n",
       "2    6000\n",
       "1    6000\n",
       "0    6000\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "84Qr9P3fSzvw",
    "outputId": "502a7ece-a062-43f2-d356-4be766ba4b7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) (60000, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = train.drop(columns = 'label')\n",
    "y_train = train[['label']]\n",
    "\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pmuY201uVwp0",
    "outputId": "1c12485b-9513-4a64-abbf-49ace878d264"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784) (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "X_test = test.drop(columns = 'label')\n",
    "y_test = test[['label']]\n",
    "\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WoFD-X8mWHQS"
   },
   "outputs": [],
   "source": [
    "# convert to float because we do not want the values to just be 0 or 1 - normalize the dataset and then divide by 255\n",
    "\n",
    "X_train = X_train.astype(np.float32) / 255\n",
    "X_test = X_test.astype(np.float32) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ve8dmW7qXF4F",
    "outputId": "4fa445db-a1e8-4e1c-b634-d1bc6658c301"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784, 3) (10000, 784, 3)\n"
     ]
    }
   ],
   "source": [
    "# for InceptionV3, we need the size to be at least 75 x 75 x 3\n",
    "\n",
    "# first change number of channels to 3\n",
    "X_train_inceptionV3 = np.dstack([X_train] * 3)\n",
    "X_test_inceptionV3 = np.dstack([X_test] * 3)\n",
    "\n",
    "print(X_train_inceptionV3.shape, X_test_inceptionV3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ddTTS2TKZXv0",
    "outputId": "93e03062-a147-4503-f37a-144f0f8c1302"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 3) (10000, 28, 28, 3)\n"
     ]
    }
   ],
   "source": [
    "# next reshape images to 28 x 28\n",
    "\n",
    "X_train_inceptionV3 = X_train_inceptionV3.reshape((-1, 28, 28, 3))\n",
    "X_test_inceptionV3 = X_test_inceptionV3.reshape((-1, 28, 28, 3))\n",
    "\n",
    "print(X_train_inceptionV3.shape, X_test_inceptionV3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "kVQJuvrIZ-58",
    "outputId": "f456ad5f-d94a-4be4-dcbb-7f0201dfc25a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 75, 75, 3) (10000, 75, 75, 3)\n"
     ]
    }
   ],
   "source": [
    "# now we must resize to 75 x 75 x 3\n",
    "\n",
    "X_train_inceptionV3 = np.asarray([img_to_array(array_to_img(img_xtr, scale=False).resize((75,75))) for img_xtr in X_train_inceptionV3])\n",
    "X_test_inceptionV3 = np.asarray([img_to_array(array_to_img(img_xte, scale=False).resize((75,75))) for img_xte in X_test_inceptionV3])\n",
    "\n",
    "print(X_train_inceptionV3.shape, X_test_inceptionV3.shape)\n",
    "\n",
    "# yay! we have the right sizes :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "b3MQwVfvcIm1",
    "outputId": "e3febb92-f84a-4ae3-ce69-11eef491adc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# one hot encoding\n",
    "y_train_inceptionV3 = to_categorical(y_train, num_classes = 10)\n",
    "y_test_inceptionV3 = to_categorical(y_test, num_classes = 10)\n",
    "\n",
    "print(y_train_inceptionV3.shape, y_test_inceptionV3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "HtYv166weL1N",
    "outputId": "aa4e1347-9113-44c3-e19a-8496383a73e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 75, 75, 3) (10000, 75, 75, 3)\n"
     ]
    }
   ],
   "source": [
    "# InceptionV3\n",
    "\n",
    "# we have to preprocess the data\n",
    "X_train_inceptionV3_pp = preprocess_input(X_train_inceptionV3)\n",
    "X_test_inceptionV3_pp = preprocess_input(X_test_inceptionV3)\n",
    "\n",
    "print(X_train_inceptionV3_pp.shape, X_test_inceptionV3_pp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "QXzRAvXeihOZ",
    "outputId": "af1a8110-135e-4ba4-fab2-b0a4710eef69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inception_v3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 75, 75, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 37, 37, 32)   864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 37, 37, 32)   96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 37, 37, 32)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 35, 35, 32)   9216        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 35, 35, 32)   96          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 35, 35, 32)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 35, 35, 64)   18432       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 35, 35, 64)   192         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 35, 35, 64)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 17, 17, 64)   0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 17, 17, 80)   5120        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 17, 17, 80)   240         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 17, 17, 80)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 15, 15, 192)  138240      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 15, 15, 192)  576         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 15, 15, 192)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 192)    0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 7, 7, 64)     12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 7, 7, 64)     192         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 7, 7, 64)     0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 7, 7, 48)     9216        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 7, 7, 96)     55296       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 7, 7, 48)     144         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 7, 7, 96)     288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 7, 7, 48)     0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 7, 7, 96)     0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 7, 7, 192)    0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 7, 7, 64)     12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 7, 7, 64)     76800       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 7, 7, 96)     82944       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 7, 7, 32)     6144        average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 7, 7, 64)     192         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 7, 7, 64)     192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 7, 7, 96)     288         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 7, 7, 32)     96          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 7, 7, 64)     0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 7, 7, 64)     0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 7, 7, 96)     0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 7, 7, 32)     0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 7, 7, 256)    0           activation_6[0][0]               \n",
      "                                                                 activation_8[0][0]               \n",
      "                                                                 activation_11[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 7, 7, 64)     16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 7, 7, 64)     192         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 7, 7, 64)     0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 7, 7, 48)     12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 7, 7, 96)     55296       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 7, 7, 48)     144         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 7, 7, 96)     288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 7, 7, 48)     0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 7, 7, 96)     0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 7, 7, 256)    0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 7, 7, 64)     16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 7, 7, 64)     76800       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 7, 7, 96)     82944       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 7, 7, 64)     16384       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 7, 7, 64)     192         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 7, 7, 64)     192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 7, 7, 96)     288         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 7, 7, 64)     192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 7, 7, 64)     0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 7, 7, 64)     0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 7, 7, 96)     0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 7, 7, 64)     0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 7, 7, 288)    0           activation_13[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 7, 7, 64)     18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 7, 7, 64)     192         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 7, 7, 64)     0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 7, 7, 48)     13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 7, 7, 96)     55296       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 7, 7, 48)     144         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 7, 7, 96)     288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 7, 7, 48)     0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 7, 7, 96)     0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 7, 7, 288)    0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 7, 7, 64)     18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 7, 7, 64)     76800       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 7, 7, 96)     82944       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 7, 7, 64)     18432       average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 7, 7, 64)     192         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 7, 7, 64)     192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 7, 7, 96)     288         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 7, 7, 64)     192         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 7, 7, 64)     0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 7, 7, 64)     0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 7, 7, 96)     0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 7, 7, 64)     0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 7, 7, 288)    0           activation_20[0][0]              \n",
      "                                                                 activation_22[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "                                                                 activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 7, 7, 64)     18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 7, 7, 64)     192         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 7, 7, 64)     0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 7, 7, 96)     55296       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 3, 3, 384)    995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 3, 3, 96)     82944       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 3, 3, 384)    1152        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 3, 3, 96)     288         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 3, 3, 384)    0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 3, 3, 96)     0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 288)    0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 3, 3, 768)    0           activation_27[0][0]              \n",
      "                                                                 activation_30[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 3, 3, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 3, 3, 128)    384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 3, 3, 128)    0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 3, 3, 128)    114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 3, 3, 128)    384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 3, 3, 128)    0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 3, 3, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 3, 3, 128)    114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 3, 3, 128)    384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 3, 3, 128)    384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 3, 3, 128)    0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 3, 3, 128)    0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 3, 3, 128)    114688      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 3, 3, 128)    114688      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 3, 3, 128)    384         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 3, 3, 128)    384         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 3, 3, 128)    0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 3, 3, 128)    0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 3, 3, 768)    0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 3, 3, 192)    147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 3, 3, 192)    172032      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 3, 3, 192)    172032      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 3, 3, 192)    147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 3, 3, 192)    576         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 3, 3, 192)    576         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 3, 3, 192)    576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 3, 3, 192)    576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 3, 3, 192)    0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 3, 3, 192)    0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 3, 3, 192)    0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 3, 3, 192)    0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 3, 3, 768)    0           activation_31[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "                                                                 activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 3, 3, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 3, 3, 160)    480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 3, 3, 160)    0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 3, 3, 160)    179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 3, 3, 160)    480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 3, 3, 160)    0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 3, 3, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 3, 3, 160)    179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 3, 3, 160)    480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 3, 3, 160)    480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 3, 3, 160)    0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 3, 3, 160)    0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 3, 3, 160)    179200      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 3, 3, 160)    179200      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 3, 3, 160)    480         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 3, 3, 160)    480         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 3, 3, 160)    0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 3, 3, 160)    0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 3, 3, 768)    0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 3, 3, 192)    147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 3, 3, 192)    215040      activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 3, 3, 192)    215040      activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 3, 3, 192)    147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 3, 3, 192)    576         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 3, 3, 192)    576         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 3, 3, 192)    576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 3, 3, 192)    576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 3, 3, 192)    0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 3, 3, 192)    0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 3, 3, 192)    0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 3, 3, 192)    0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 3, 3, 768)    0           activation_41[0][0]              \n",
      "                                                                 activation_44[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "                                                                 activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 3, 3, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 3, 3, 160)    480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 3, 3, 160)    0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 3, 3, 160)    179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 3, 3, 160)    480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 3, 3, 160)    0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 3, 3, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 3, 3, 160)    179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 3, 3, 160)    480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 3, 3, 160)    480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 3, 3, 160)    0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 3, 3, 160)    0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 3, 3, 160)    179200      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 3, 3, 160)    179200      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 3, 3, 160)    480         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 3, 3, 160)    480         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 3, 3, 160)    0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 3, 3, 160)    0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 3, 3, 768)    0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 3, 3, 192)    147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 3, 3, 192)    215040      activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 3, 3, 192)    215040      activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 3, 3, 192)    147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 3, 3, 192)    576         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 3, 3, 192)    576         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 3, 3, 192)    576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 3, 3, 192)    576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 3, 3, 192)    0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 3, 3, 192)    0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 3, 3, 192)    0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 3, 3, 192)    0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 3, 3, 768)    0           activation_51[0][0]              \n",
      "                                                                 activation_54[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "                                                                 activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 3, 3, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 3, 3, 192)    576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 3, 3, 192)    0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 3, 3, 192)    258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 3, 3, 192)    576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 3, 3, 192)    0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 3, 3, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 3, 3, 192)    258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 3, 3, 192)    576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 3, 3, 192)    576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 3, 3, 192)    0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 3, 3, 192)    0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 3, 3, 192)    258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 3, 3, 192)    258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 3, 3, 192)    576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 3, 3, 192)    576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 3, 3, 192)    0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 3, 3, 192)    0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 3, 3, 768)    0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 3, 3, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 3, 3, 192)    258048      activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 3, 3, 192)    258048      activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 3, 3, 192)    147456      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 3, 3, 192)    576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 3, 3, 192)    576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 3, 3, 192)    576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 3, 3, 192)    576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 3, 3, 192)    0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 3, 3, 192)    0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 3, 3, 192)    0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 3, 3, 192)    0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 3, 3, 768)    0           activation_61[0][0]              \n",
      "                                                                 activation_64[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "                                                                 activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 3, 3, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 3, 3, 192)    576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 3, 3, 192)    0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 3, 3, 192)    258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 3, 3, 192)    576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 3, 3, 192)    0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 3, 3, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 3, 3, 192)    258048      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 3, 3, 192)    576         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 3, 3, 192)    576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 3, 3, 192)    0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 3, 3, 192)    0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 1, 1, 320)    552960      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 1, 1, 192)    331776      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 1, 1, 320)    960         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 1, 1, 192)    576         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 1, 1, 320)    0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 1, 1, 192)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 1, 1, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 1, 1, 1280)   0           activation_72[0][0]              \n",
      "                                                                 activation_76[0][0]              \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 1, 1, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 1, 1, 448)    1344        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 1, 1, 448)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 1, 1, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 1, 1, 384)    1548288     activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 1, 1, 384)    1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 1, 1, 384)    1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 1, 1, 384)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 1, 1, 384)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 1, 1, 384)    442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 1, 1, 384)    442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 1, 1, 384)    442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 1, 1, 384)    442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 1, 1, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 1, 1, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 1, 1, 384)    1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 1, 1, 384)    1152        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 1, 1, 384)    1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 1, 1, 384)    1152        conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 1, 1, 192)    245760      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 1, 1, 320)    960         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 1, 1, 384)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 1, 1, 384)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 1, 1, 384)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 1, 1, 384)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 1, 1, 192)    576         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 1, 1, 320)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 1, 1, 768)    0           activation_79[0][0]              \n",
      "                                                                 activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1, 1, 768)    0           activation_83[0][0]              \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 1, 1, 192)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 1, 1, 2048)   0           activation_77[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 1, 1, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 1, 1, 448)    1344        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 1, 1, 448)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 1, 1, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 1, 1, 384)    1548288     activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 1, 1, 384)    1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 1, 1, 384)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 1, 1, 384)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 1, 1, 384)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 1, 1, 384)    442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 1, 1, 384)    442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 1, 1, 384)    442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 1, 1, 384)    442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, 1, 1, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 1, 1, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 1, 1, 384)    1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 1, 1, 384)    1152        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 1, 1, 384)    1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 1, 1, 384)    1152        conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 1, 1, 192)    393216      average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 1, 1, 320)    960         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 1, 1, 384)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 1, 1, 384)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 1, 1, 384)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 1, 1, 384)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 1, 1, 192)    576         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 1, 1, 320)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 1, 1, 768)    0           activation_88[0][0]              \n",
      "                                                                 activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 1, 1, 768)    0           activation_92[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 1, 1, 192)    0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 1, 1, 2048)   0           activation_86[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 activation_94[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 21,768,352\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# load base model\n",
    "\n",
    "incV3_base = InceptionV3(include_top = False, weights = 'imagenet', input_shape = (75, 75, 3))\n",
    "incV3_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dym3qf6YjIoZ"
   },
   "outputs": [],
   "source": [
    "# need to continue to add some layers -- see Keras documentation\n",
    "x = incV3_base.output\n",
    "\n",
    "# add Global Average Pooling as a Flatten layer (also used in Keras documentation)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# add a Dense layer (fully-connected layer)\n",
    "x = Dense(units = 1024, activation = 'relu')(x)\n",
    "\n",
    "# add final Dense layer with units = # classes\n",
    "predictions = Dense(units = 10, activation = 'softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fdw5m4LTlQZg"
   },
   "outputs": [],
   "source": [
    "# build final model\n",
    "\n",
    "model = Model(inputs = incV3_base.input, outputs = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AOZE8OOUleMX"
   },
   "outputs": [],
   "source": [
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers -- straight from Keras.io documentation\n",
    "for layer in incV3_base.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mWXqoyDzlj_t"
   },
   "outputs": [],
   "source": [
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "hKQPdHNV2A27",
    "outputId": "dac3f30f-6bf1-4cef-941a-8d0a41acb7b1"
   },
   "outputs": [],
   "source": [
    "#keras.utils.plot_model(model, \"Updated InceptionV3.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RpqcQCZymgI0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 414s 7ms/step - loss: 2.1081 - accuracy: 0.2265\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 417s 7ms/step - loss: 2.0432 - accuracy: 0.2525\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 417s 7ms/step - loss: 2.0145 - accuracy: 0.2633\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 417s 7ms/step - loss: 1.9979 - accuracy: 0.2718\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 417s 7ms/step - loss: 1.9864 - accuracy: 0.2764\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 417s 7ms/step - loss: 1.9755 - accuracy: 0.2809\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 417s 7ms/step - loss: 1.9750 - accuracy: 0.2808\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 417s 7ms/step - loss: 1.9622 - accuracy: 0.2819\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 417s 7ms/step - loss: 1.9612 - accuracy: 0.2877\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 417s 7ms/step - loss: 1.9574 - accuracy: 0.2878\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 417s 7ms/step - loss: 1.9544 - accuracy: 0.2868\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 417s 7ms/step - loss: 1.9505 - accuracy: 0.2892\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 417s 7ms/step - loss: 1.9430 - accuracy: 0.2939\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 417s 7ms/step - loss: 1.9440 - accuracy: 0.2918\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 417s 7ms/step - loss: 1.9371 - accuracy: 0.2962\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 417s 7ms/step - loss: 1.9392 - accuracy: 0.2956\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 417s 7ms/step - loss: 1.9347 - accuracy: 0.2953\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 417s 7ms/step - loss: 1.9353 - accuracy: 0.2979\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 417s 7ms/step - loss: 1.9338 - accuracy: 0.2956\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 417s 7ms/step - loss: 1.9300 - accuracy: 0.2987\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 417s 7ms/step - loss: 1.9310 - accuracy: 0.2986\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 417s 7ms/step - loss: 1.9270 - accuracy: 0.2975\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 417s 7ms/step - loss: 1.9234 - accuracy: 0.2997\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 417s 7ms/step - loss: 1.9221 - accuracy: 0.3009\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 417s 7ms/step - loss: 1.9235 - accuracy: 0.3018\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 417s 7ms/step - loss: 1.9241 - accuracy: 0.3011\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 417s 7ms/step - loss: 1.9218 - accuracy: 0.3006\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 417s 7ms/step - loss: 1.9218 - accuracy: 0.2995\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 417s 7ms/step - loss: 1.9167 - accuracy: 0.3049\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 417s 7ms/step - loss: 1.9211 - accuracy: 0.3025\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 417s 7ms/step - loss: 1.9183 - accuracy: 0.3031\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 417s 7ms/step - loss: 1.9127 - accuracy: 0.3045\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 417s 7ms/step - loss: 1.9129 - accuracy: 0.3042\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 417s 7ms/step - loss: 1.9172 - accuracy: 0.3015\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 417s 7ms/step - loss: 1.9205 - accuracy: 0.3033\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 417s 7ms/step - loss: 1.9144 - accuracy: 0.3049\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 417s 7ms/step - loss: 1.9116 - accuracy: 0.3045\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 417s 7ms/step - loss: 1.9088 - accuracy: 0.3070\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 417s 7ms/step - loss: 1.9096 - accuracy: 0.3089\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 417s 7ms/step - loss: 1.9093 - accuracy: 0.3052\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 417s 7ms/step - loss: 1.9080 - accuracy: 0.3070\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 417s 7ms/step - loss: 1.9092 - accuracy: 0.3056\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 414s 7ms/step - loss: 1.9118 - accuracy: 0.3063\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 410s 7ms/step - loss: 1.9073 - accuracy: 0.3059\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 410s 7ms/step - loss: 1.9108 - accuracy: 0.3040\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 410s 7ms/step - loss: 1.9125 - accuracy: 0.3019\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 410s 7ms/step - loss: 1.9086 - accuracy: 0.3076\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 410s 7ms/step - loss: 1.9107 - accuracy: 0.3067\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 410s 7ms/step - loss: 1.9074 - accuracy: 0.3099\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 410s 7ms/step - loss: 1.9041 - accuracy: 0.3096\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "hist = model.fit(X_train_inceptionV3_pp, y_train_inceptionV3, batch_size = 32, epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qEA59JtYmwVd"
   },
   "outputs": [],
   "source": [
    "# save model to disk\n",
    "model.save('InceptionV3_V1_0530')\n",
    "\n",
    "# keras.models.load_models(\"path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3Ij-pGt9-6ri"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 70s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "scores = model.evaluate(X_test_inceptionV3_pp, y_test_inceptionV3)\n",
    "\n",
    "# prediction classes\n",
    "preds = model.predict(X_test_inceptionV3_pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.7892779930114746, 0.10080000013113022]\n"
     ]
    }
   ],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01370344 0.01162986 0.0189743  0.1270463  0.0326509  0.1533899\n",
      "  0.17671824 0.01912455 0.24624176 0.20052066]]\n"
     ]
    }
   ],
   "source": [
    "print(preds[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZyyBFknf-BFU"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "history_dict = hist.history\n",
    "loss_values = history_dict['loss']\n",
    "#val_loss_values = history_dict['val_loss']\n",
    "acc_values = history_dict['accuracy']\n",
    "#val_acc_values = history_dict['val_acc']\n",
    "epochs = range(0, 50)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss_values)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(epochs, acc_values)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training Accuracy')\n",
    "plt.gca().set_yticklabels(['{:.0f}%'.format(x*100) for x in plt.gca().get_yticks()])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "InceptionV3",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
